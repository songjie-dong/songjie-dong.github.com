<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 操作系统 | All Things Coding]]></title>
  <link href="http://songjie-dong.github.com/blog/categories/操作系统/atom.xml" rel="self"/>
  <link href="http://songjie-dong.github.com/"/>
  <updated>2014-01-05T00:03:53+08:00</updated>
  <id>http://songjie-dong.github.com/</id>
  <author>
    <name><![CDATA[Songjie Dong]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[dalvik内存分配无碎片的思考]]></title>
    <link href="http://songjie-dong.github.com/blog/2012/09/23/shen-ru-li-jie-ji-suan-ji-malloc/"/>
    <updated>2012-09-23T16:56:00+08:00</updated>
    <id>http://songjie-dong.github.com/blog/2012/09/23/shen-ru-li-jie-ji-suan-ji-malloc</id>
    <content type="html"><![CDATA[<p>最近看dalvik的gc机制,发现没啥太多资料,但是注意到了dalvik并没有做内存整理,也就是compact阶段,传言内部有一些机制来避免碎片形成,很好奇,分析一下</p>

<h2>一些概念</h2>

<h3>动态内存分配器 dynamic memory allocator</h3>

<p>何为<strong>动态内存分配</strong>,大家知道,在有些时候我们并不能一开始就知道需要用到的内存,比如读取一班级的所有同学信息到一个数组,数组的大小取决于运行时以某种方式查询获知,于是我们需要在运行时分配内存.无论是在vm上跑的java还是在操作系统里跑的c,对于内存的使用都会包含一下的基本部分,栈,固定的分配好的区域,堆,栈里面的数据是操作系统或vm会处理分配和释放,堆(heap)则负责动态内存分配,java和c不同的是jvm使用的<strong>隐式分配器</strong>,而c则是<strong>显式分配器</strong>,区别就是一个有gc,new出来就可以,另一个则由我们自己显式malloc和free.</p>

<h3>碎片</h3>

<p>jvm的<strong>current mark and sweep</strong>收集器提供了可选的compact功能,即整理内存,或者形象点说就是把内存压实,把空的缝隙的给挤掉.这里的碎片指的是<strong>外部碎片</strong>.我们把内存看成一大块连续的内存空间,而且空间可以<strong>伸缩</strong>(<strong>sbrk</strong>),当我们需要使用内存的时候,则在这块空间中寻找合适的位置存放数据,假设我们每次都从heap的头位置开始寻找,一旦找到合适的闲置块就分配,free时则直接标记该块未使用这种方式,进程运行初期总是分配小块内存使用,于是在运行一段时候后,整个heap被分割成了很多的小块,此时如果突然开始出现大数据块的分配请求,则很可能无法找到合适的位置只能请求新的空间.(当然这是malloc极端简单的分配策略)</p>

<p><strong>内部碎片</strong>是相对于外部碎片而言的,讨论内部碎片往往意味着分配器采用了不同于刚刚的分配策略,以<strong>memcached</strong>为例,memcached的内存管理策略是将内存分为不同的classes,假设一个class总长度1m,然后将其等分为固定大小的chunk,比如等分成16份,则每个chunk为64k,一个chunk为最小的分配单元,memcached用<strong>O(1)</strong>(为什么可以做到O(1),用上述的简单内存分配策略能否做到呢?)的时间寻找最合适的chunk来存储数据,但是无论如何分配,每个chunk都很难被100%使用,这就产生了内部碎片.划分classes的方法可以很好的提高分配效率,但同时也需要一些<strong>启发式的策略</strong>来优化内存有效使用率.PS:由于memcached的内存分配很死板,如果内存已经被各种不同chunk大小的classes占满,class分布完成则无法改变,这等于是把启发式策略做了一半,现在貌似在改进了.</p>

<h2>经典</h2>

<ul>
<li>dlmalloc
doug lea大神的作品,参见<a href="http://gee.cs.oswego.edu/dl/html/malloc.html">A Memory Allocator</a>,此文讲的很全面,特别是对于何为优秀的内存分配器,提了八个点.里面的一些分配器实现的理念被后续沿用,算是必读文章之一,不过内容有些滞后,很多dlmalloc后续的更新并没有描述.</li>
<li>jemalloc
增加了对于多核的分配优化,将内存分成不同的Arena,避免部分场景分配时竞争带来的开销,jvm中同样有类似的概念TLAB(Thead local allocate buffer),对于小对象的分配直接在thread独占的区域分配.记得里面还提到了缓存作色的优化.</li>
<li>tcmalloc
类似jemalloc,有些测试结果表明性能更好,缺点是需要关注内存的有效使用率,分配速度和内存有效使用率是分配器设计时需要取舍的.PS:如果想研究分配器,可以读读代码,应该很不错.</li>
</ul>


<h2>分配器总结</h2>

<p><strong>多核,多线程</strong>的分配优化,<strong>缓存作色</strong>,内存有效使用率(使用划分固定大小chunk的机制会提高分配的效率,降低分配高性能实现的复杂度,但不可避免的会有内存有效使用率的问题,需要一些启发式的优化策略,具体取舍看场景,内存很宝贵则可以在分配速度上让步,二者难以兼得,相关知识建议直接看深入理解计算机相关章节,想挖坑的可以看论文),这些问题都是现代分配器高性能的关键词.</p>

<h2>题外话</h2>

<p>回过头来看jvm,为啥老有碎片呢...难道是为了顾及一次书写,到处执行，so内部实现的内存管理实现的通用内存分配来跨平台?问题很多哇,可时间不多~,后续研究，碎叫~</p>
]]></content>
  </entry>
  
</feed>
